library(car)
library(corrplot)
library(dplyr)
library(faraway)
library(lmtest)
library(MASS)
library(nortest)
library(RColorBrewer)
wine <- read.csv("C:\\Users\\Nikola\\Documents\\Nikola Chmielewska\\R\\Datasets\\winequalityN.csv")
str(wine)
unique(wine$type)
summary(wine)
(sapply(wine, function(x) {sum(is.na(x))}))
wine_clean <- na.omit(wine) #usuwa wiersze zawierające wartości NA
(sapply(wine_clean, function(x) {sum(is.na(x))}))
white_wine <- subset(wine_clean, type == "white")
red_wine <- subset(wine_clean, type == "red")
white_numeric <- white_wine[sapply(white_wine, is.numeric)]
N <- nrow(white_numeric)
I <- (1:N)
set.seed(300)
I_l <- sample.int(N, size = round(N/2)) #50% danych
I_v <- sample(setdiff(I, I_l), size = round(N/4)) #25% danych
I_t <- setdiff(setdiff(I, I_l), I_v) #25% danych
lrn <- white_numeric[I_l,] #próba ucząca
val <- white_numeric[I_v,] #próba walidacyjna
tst <- white_numeric[I_t,] #próba testowa
white_matrix <- cor(lrn)
corrplot(white_matrix, type = "lower")
for(i in 2:countM){
print(paste(get_name(1), 'vs', get_name(i), sep=' '))
print(anova(get_model(1), get_model(i)))
}
library(car)
library(corrplot)
library(dplyr)
library(faraway)
library(lmtest)
library(MASS)
library(nortest)
library(RColorBrewer)
wine <- read.csv("C:\\Users\\Nikola\\Documents\\Nikola Chmielewska\\R\\Datasets\\winequalityN.csv")
str(wine)
unique(wine$type)
summary(wine)
(sapply(wine, function(x) {sum(is.na(x))}))
wine_clean <- na.omit(wine) #usuwa wiersze zawierające wartości NA
(sapply(wine_clean, function(x) {sum(is.na(x))}))
white_wine <- subset(wine_clean, type == "white")
red_wine <- subset(wine_clean, type == "red")
white_numeric <- white_wine[sapply(white_wine, is.numeric)]
N <- nrow(white_numeric)
I <- (1:N)
set.seed(300)
I_l <- sample.int(N, size = round(N/2)) #50% danych
I_v <- sample(setdiff(I, I_l), size = round(N/4)) #25% danych
I_t <- setdiff(setdiff(I, I_l), I_v) #25% danych
lrn <- white_numeric[I_l,] #próba ucząca
val <- white_numeric[I_v,] #próba walidacyjna
tst <- white_numeric[I_t,] #próba testowa
white_matrix <- cor(lrn)
corrplot(white_matrix, type = "lower")
models <<- list()
countM  = 0
add_model = function(name, model, ispca){
models <<- append(models, list(name, model, ispca))
countM <<- countM + 1
}
get_name  = function(index){models[[index*3-3+1]]}
get_model = function(index){models[[index*3-3+2]]}
is_pca    = function(index){models[[index*3-3+3]]}
add_model('full',                 lm(quality ~ .,                            data = lrn), FALSE)
add_model('no sugar',             lm(quality ~ . - residual.sugar,           data = lrn), FALSE)
add_model('no alcohol',           lm(quality ~ .                  - alcohol, data = lrn), FALSE)
add_model('no sugar, no alcohol', lm(quality ~ . - residual.sugar - alcohol, data = lrn), FALSE)
for(i in 1:countM){
print(get_name(i))
print(summary(get_model(i)))
}
for(i in 2:countM){
print(paste(get_name(1), 'vs', get_name(i), sep=' '))
print(anova(get_model(1), get_model(i)))
}
library(car)
library(corrplot)
library(dplyr)
library(faraway)
library(lmtest)
library(MASS)
library(nortest)
library(RColorBrewer)
wine <- read.csv("C:\\Users\\Nikola\\Documents\\Nikola Chmielewska\\R\\Datasets\\winequalityN.csv")
str(wine)
unique(wine$type)
summary(wine)
(sapply(wine, function(x) {sum(is.na(x))}))
wine_clean <- na.omit(wine) #usuwa wiersze zawierające wartości NA
(sapply(wine_clean, function(x) {sum(is.na(x))}))
white_wine <- subset(wine_clean, type == "white")
red_wine <- subset(wine_clean, type == "red")
white_numeric <- white_wine[sapply(white_wine, is.numeric)]
N <- nrow(white_numeric)
I <- (1:N)
set.seed(300)
I_l <- sample.int(N, size = round(N/2)) #50% danych
I_v <- sample(setdiff(I, I_l), size = round(N/4)) #25% danych
I_t <- setdiff(setdiff(I, I_l), I_v) #25% danych
lrn <- white_numeric[I_l,] #próba ucząca
val <- white_numeric[I_v,] #próba walidacyjna
tst <- white_numeric[I_t,] #próba testowa
white_matrix <- cor(lrn)
corrplot(white_matrix, type = "lower")
models <<- list()
countM  = 0
add_model = function(name, model, ispca){
models <<- append(models, list(name, model, ispca))
countM <<- countM + 1
}
get_name  = function(index){models[[index*3-3+1]]}
get_model = function(index){models[[index*3-3+2]]}
is_pca    = function(index){models[[index*3-3+3]]}
add_model('full',                 lm(quality ~ .,                            data = lrn), FALSE)
add_model('no sugar',             lm(quality ~ . - residual.sugar,           data = lrn), FALSE)
add_model('no alcohol',           lm(quality ~ .                  - alcohol, data = lrn), FALSE)
add_model('no sugar, no alcohol', lm(quality ~ . - residual.sugar - alcohol, data = lrn), FALSE)
for(i in 1:countM){
print(get_name(i))
print(summary(get_model(i)))
}
for(i in 2:countM){
print(paste(get_name(1), 'vs', get_name(i), sep=' '))
print(anova(get_model(1), get_model(i)))
}
elim <- add_model('no acid', lm(quality ~ . - citric.acid, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
add_model('no acid, no chlorides', lm(quality ~ . - citric.acid - chlorides, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
add_model('no acid, no chlorides, no totalsulf', lm(quality ~ . - citric.acid - chlorides - total.sulfur.dioxide, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
par(mfrow = c(1, 2))
pca     <- prcomp(lrn[1:11], scale. = TRUE)
pca_var <- pca$sdev^2
plot(pca_var / sum(pca_var), xlab = "Składowe główne",
ylab = "Proporcja wariancji objaśnianej",
type = "b")
pca_data <- data.frame(quality = lrn$quality, pca$x)
corrplot(cor(pca_data), type = "lower")
pca_base <- add_model('pca', lm(quality ~ ., data = pca_data), TRUE)
summary(get_model(countM))
add_model('pca no pc6', lm(quality ~ . - PC6, data = pca_data), TRUE)
anova(get_model(pca_base), get_model(countM))
summary(get_model(countM))
add_model('pca no pc6, no pc7', lm(quality ~ . - PC6 - PC7, data = pca_data), TRUE)
anova(get_model(pca_base), get_model(countM))
summary(get_model(countM))
cook_base = countM
cook_statistics = function(name, model, ispca){
cook <- cooks.distance(model)
plot(cook, xlab = "Indeksy",  ylab = paste("Odległości(", name, ")"))
if(max(cook) >= 1){
name <- paste('cook', name, sep = ' ')
while(max(cook) >= 1){
model <- update(model, subset = (cook < max(cook)))
cook  <- cooks.distance(model)
}
add_model(name, model, ispca)
}
}
layout(matrix(c(1,2,3,4,5,6,7,8,9,10), 2, 5, byrow = TRUE))
for(i in 1:cook_base){
name  <- get_name(i)
model <- get_model(i)
cook_statistics(name, model, is_pca(i))
}
mtext("Odległość Cooka", side=3, outer=TRUE, line=-3)
par(mfrow = c(9, 3))
leverages <- mapply(function(index){
name  <- get_name(index)
model <- get_model(index)
lev   <- hat(model.matrix(model))
p <- (index - 1) %% 3
q <- ifelse((index - 1) %% 6 >= 3, 0, 1)
par(fig = c(1/3 * p,1/3 + 1/3 * p, 0.5 * q, 0.5 + 0.5 * q), new = (index %% 6 != 1))
plot(lev, xlab = "Indeksy", ylab = "Obserwacje wpływowe", main = name)
abline(h = 2 * sum(lev) / nrow(model$model), col = 'red')
lev
}, 1:countM)
data.frame(names = mapply(get_name, 1:countM),
percentages = mapply(function(index){
model <- get_model(index)
lev   <- leverages[[index]]
paste(round(sum( ifelse(lev > 2 * sum(lev) / nrow(model$model), 1, 0)) / nrow(model$model) * 100, 2), '%')
}, 1:countM))
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
plot(model$fit, model$res, xlab="Dopasowane", ylab="Reszty", main = get_name(i))
abline(h = 0, col = 'red')
data.frame(names = mapply(get_name, 1:countM),
percentages = mapply(function(index){
model <- get_model(index)
lev   <- leverages[[index]]
paste(round(sum( ifelse(lev > 2 * sum(lev) / nrow(model$model), 1, 0)) / nrow(model$model) * 100, 2), '%')
}, 1:countM))
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
plot(model$fit, model$res, xlab="Dopasowane", ylab="Reszty", main = get_name(i))
abline(h = 0, col = 'red')
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
plot(model$fit, model$res, xlab="Dopasowane", ylab="Reszty", main = get_name(i))
abline(h = 0, col = 'red')}
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
qqnorm(rstudent(model), xlab = "Teoretyczne Kwantyle", ylab = "Studentyzowane reszty", main = get_name(i))
abline(0,1)
}
wine1 <- white_numeric
wine1$quality <- factor(wine1$quality)
library(car)
library(corrplot)
library(dplyr)
library(faraway)
library(lmtest)
library(MASS)
library(nortest)
library(RColorBrewer)
wine <- read.csv("C:\\Users\\Nikola\\Documents\\Nikola Chmielewska\\R\\Datasets\\winequalityN.csv")
str(wine)
unique(wine$type)
summary(wine)
(sapply(wine, function(x) {sum(is.na(x))}))
wine_clean <- na.omit(wine) #usuwa wiersze zawierające wartości NA
(sapply(wine_clean, function(x) {sum(is.na(x))}))
white_wine <- subset(wine_clean, type == "white")
white_numeric <- white_wine[sapply(white_wine, is.numeric)]
N <- nrow(white_numeric)
I <- (1:N)
set.seed(300)
I_l <- sample.int(N, size = round(N/2)) #50% danych
I_v <- sample(setdiff(I, I_l), size = round(N/4)) #25% danych
I_t <- setdiff(setdiff(I, I_l), I_v) #25% danych
lrn <- white_numeric[I_l,] #próba ucząca
val <- white_numeric[I_v,] #próba walidacyjna
tst <- white_numeric[I_t,] #próba testowa
white_matrix <- cor(lrn)
corrplot(white_matrix, type = "lower")
models <<- list()
countM  = 0
add_model = function(name, model, ispca){
models <<- append(models, list(name, model, ispca))
countM <<- countM + 1
}
get_name  = function(index){models[[index*3-3+1]]}
get_model = function(index){models[[index*3-3+2]]}
is_pca    = function(index){models[[index*3-3+3]]}
add_model('full',                 lm(quality ~ .,                            data = lrn), FALSE)
add_model('no sugar',             lm(quality ~ . - residual.sugar,           data = lrn), FALSE)
add_model('no alcohol',           lm(quality ~ .                  - alcohol, data = lrn), FALSE)
add_model('no sugar, no alcohol', lm(quality ~ . - residual.sugar - alcohol, data = lrn), FALSE)
for(i in 1:countM){
print(get_name(i))
print(summary(get_model(i)))
}
for(i in 2:countM){
print(paste(get_name(1), 'vs', get_name(i), sep=' '))
print(anova(get_model(1), get_model(i)))
}
elim <- add_model('no acid', lm(quality ~ . - citric.acid, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
add_model('no acid, no chlorides', lm(quality ~ . - citric.acid - chlorides, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
add_model('no acid, no chlorides, no totalsulf', lm(quality ~ . - citric.acid - chlorides - total.sulfur.dioxide, data = lrn), FALSE)
anova(get_model(1), get_model(countM))
summary(get_model(countM))
par(mfrow = c(1, 2))
pca     <- prcomp(lrn[1:11], scale. = TRUE)
pca_var <- pca$sdev^2
plot(pca_var / sum(pca_var), xlab = "Składowe główne",
ylab = "Proporcja wariancji objaśnianej",
type = "b")
pca_data <- data.frame(quality = lrn$quality, pca$x)
corrplot(cor(pca_data), type = "lower")
pca_base <- add_model('pca', lm(quality ~ ., data = pca_data), TRUE)
summary(get_model(countM))
add_model('pca no pc6', lm(quality ~ . - PC6, data = pca_data), TRUE)
anova(get_model(pca_base), get_model(countM))
summary(get_model(countM))
add_model('pca no pc6, no pc7', lm(quality ~ . - PC6 - PC7, data = pca_data), TRUE)
anova(get_model(pca_base), get_model(countM))
summary(get_model(countM))
cook_base = countM
cook_statistics = function(name, model, ispca){
cook <- cooks.distance(model)
plot(cook, xlab = "Indeksy",  ylab = paste("Odległości(", name, ")"))
if(max(cook) >= 1){
name <- paste('cook', name, sep = ' ')
while(max(cook) >= 1){
model <- update(model, subset = (cook < max(cook)))
cook  <- cooks.distance(model)
}
add_model(name, model, ispca)
}
}
layout(matrix(c(1,2,3,4,5,6,7,8,9,10), 2, 5, byrow = TRUE))
for(i in 1:cook_base){
name  <- get_name(i)
model <- get_model(i)
cook_statistics(name, model, is_pca(i))
}
mtext("Odległość Cooka", side=3, outer=TRUE, line=-3)
par(mfrow = c(9, 3))
leverages <- mapply(function(index){
name  <- get_name(index)
model <- get_model(index)
lev   <- hat(model.matrix(model))
p <- (index - 1) %% 3
q <- ifelse((index - 1) %% 6 >= 3, 0, 1)
par(fig = c(1/3 * p,1/3 + 1/3 * p, 0.5 * q, 0.5 + 0.5 * q), new = (index %% 6 != 1))
plot(lev, xlab = "Indeksy", ylab = "Obserwacje wpływowe", main = name)
abline(h = 2 * sum(lev) / nrow(model$model), col = 'red')
lev
}, 1:countM)
data.frame(names = mapply(get_name, 1:countM),
percentages = mapply(function(index){
model <- get_model(index)
lev   <- leverages[[index]]
paste(round(sum( ifelse(lev > 2 * sum(lev) / nrow(model$model), 1, 0)) / nrow(model$model) * 100, 2), '%')
}, 1:countM))
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
plot(model$fit, model$res, xlab="Dopasowane", ylab="Reszty", main = get_name(i))
abline(h = 0, col = 'red')}
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
qqnorm(rstudent(model), xlab = "Teoretyczne Kwantyle", ylab = "Studentyzowane reszty", main = get_name(i))
abline(0,1)
}
data.frame("Nazwa modelu" = mapply(get_name, 1:countM),
"p-value" = mapply(function(i){ shapiro.test(get_model(i)$residuals)$p.value }, 1:countM))
par(mfrow = c(ceiling(countM / 4), 4))
for(i in 1:countM){
model <- get_model(i)
p <- (i - 1) %% 4
q <- ifelse((i - 1) %% 8 >= 4, 0, 1)
par(fig = c(1/4 * p, 1/4 + 1/4 * p, 0.5 * q, 0.5 + 0.5 * q), new = (i %% 8 != 1))
plot(model$fit, model$res, xlab = "Zmienne dopasowane", ylab = "Zmienne resztowe", main = get_name(i))
abline(h = 0, col = 'red')
}
data.frame("Nazwa modelu" = mapply(get_name, 1:countM),
"p-value" = mapply(function(i){ gqtest(get_model(i))$p.value }, 1:countM))
data.frame("Nazwa modelu" = mapply(get_name, 1:countM),
"p-value" = mapply(function(i){ durbinWatsonTest(get_model(i))$p }, 1:countM))
VIF = function(i){
data.frame("Nazwa" = get_name(i), t(vif(get_model(i))))
}
data.frame("Nazwa modelu" = mapply(get_name, 1:countM),
"Skorygowany współczynnik determinacji"  = mapply(function(index){summary(get_model(index))$adj.r.squared}, 1:countM),
"Estymator wariancji błędów" = mapply(function(index){summary(get_model(index))$sigma}, 1:countM),
check.names = FALSE)
pca_val <- as.data.frame(predict(pca, newdata = val[1:11]))
pca_tst <- as.data.frame(predict(pca, newdata = tst[1:11]))
prediction_summary <- data.frame(matrix(ncol = 4, nrow = 0, dimnames = list(NULL, c("Nazwa", "RSS", "Odsetek popr","Odsetek róż"))))
make_prediction = function(index, non_pca, iff_pca){
name  <- get_name(index)
model <- get_model(index)
if(is_pca(index)){
prediction <- round(predict(model, iff_pca))
}else{
prediction <- round(predict(model, non_pca[1:11]))
}
prediction_summary[nrow(prediction_summary) + 1,] <<- c(name,
sum((prediction - non_pca[12])^2),
sum(non_pca[12] == prediction, na.rm = TRUE) / nrow(non_pca[12]) * 100,
sum(abs(non_pca[12] - prediction) <= 1)/ nrow(non_pca[12]) * 100)
}
for(i in 1:countM){ make_prediction(i, val, pca_val) }
prediction_summary
prediction_summary = NULL
prediction_summary <- data.frame(matrix(ncol = 4, nrow = 0, dimnames = list(NULL, c("Nazwa", "RSS", "odsetek popr. kl","Odsetek kl. o 1"))))
make_prediction(9, tst, pca_tst)
prediction_summary
wine1 <- white_numeric
wine1$quality <- factor(wine1$quality)
lrn2 <- wine1[I_l,]
val2 <- wine1[I_v,]
tst2 <- wine1[I_t,]
g.plr <- polr(quality ~ ., data = lrn2)
g.plr
summary(g.plr)
pr_log1 <- predict(g.plr, val2[,1:11], type="class")
val21 <- as.numeric(val2$quality)
pr_log11 <- as.numeric(pr_log1)
sum((pr_log11-val21)^2)
o_lr = step(g.plr)
summary(o_lr)
anova(g.plr,o_lr)
pr_log2<-predict(o_lr, val2[,1:11],type="class")
val21<- as.numeric(val2$quality)
pr_log12 <- as.numeric(pr_log2)
sum((pr_log12-val21)^2)
